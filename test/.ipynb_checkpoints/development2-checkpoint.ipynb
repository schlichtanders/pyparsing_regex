{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyparsing as pp\n",
    "import regex\n",
    "import sys\n",
    "from itertools import izip\n",
    "import itertools as it\n",
    "from copy import copy, deepcopy\n",
    "from collections import Sequence\n",
    "import abc\n",
    "import operator as op\n",
    "from collections import defaultdict\n",
    "from overrides import overrides\n",
    "import inspect\n",
    "from contextlib import contextmanager\n",
    "\n",
    "range = xrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from meta import lift, relift, LiftableFrom\n",
    "from mixin import Listenable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deleteallbutone(l, elm):\n",
    "    one = False\n",
    "    for i in l:\n",
    "        if i == elm and not one:\n",
    "            one = True\n",
    "            yield i\n",
    "        elif i == elm:\n",
    "            continue #pass\n",
    "        else:\n",
    "            yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Count(object):\n",
    "    \"\"\" future-like counting object\n",
    "    \n",
    "    The first time the attribute ``value`` is accessed, it gets computed by counting onwards from the total_count\n",
    "    \"\"\"\n",
    "    total_count = 1\n",
    "    \n",
    "    @staticmethod\n",
    "    def reset():\n",
    "        Count.total_count = 1\n",
    "        \n",
    "    def __init__(self, _value=None):\n",
    "        self._value = _value\n",
    "    \n",
    "    def __copy__(self):\n",
    "        return Count(self._value)\n",
    "    \n",
    "    @property\n",
    "    def value(self):\n",
    "        if self._value is None:\n",
    "            self._value = Count.total_count\n",
    "            Count.total_count += 1\n",
    "        return self._value\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self._value or \"?\")\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## general tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "regex.finditer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "regex.match(r\"(?:(ab)(cd))?(ef)\", \"ef\").captures(3)[1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "expr = pp.Literal(\"ab\") + pp.Literal(\"cd\")\n",
    "e1 = expr.setResultsName(\"key1\", listAllMatches=True)\n",
    "e2 = (pp.Literal(\"ef\"))(\"key2\")\n",
    "expr_key =  pp.Group(e1 + e2 + e1 + e2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "((e1 + \"ef\")(\"key1\")(\"key3\") +pp.Literal(\"gh\")(\"key1\")).parseString(\"ab cd ef gh\")[\"key3\"]\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "e2.parseString(\"ef\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "e2.parseString(\"ef\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "eP = expr_key.setResultsName(\"keyP\", listAllMatches=True)\n",
    "\n",
    "(eP+eP).parseString(\"ab cd ef ab cd ef ab cd ef ab cd ef\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "for i in (expr_key).parseString(\"ab cd ef ab cd ef ab cd ef ab cd ef\")[0]: print i"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "regex.match(r\"(?:z(?!ab))\", \"sadsjkfkjhsaabdasdfa\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "regex.findall(r\"(a(?:b)?+)\", \"abbbbaab\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "regex.escape(\"?.+ab\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "d = \"(?:dshja)\"\n",
    "d2 = \"hjkds\"\n",
    "m = begins_suppressed.match(d)\n",
    "m.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parser specific tests"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "w = Word(\"abc\") + \"?\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "r = w.parseString(\"abcde\")\n",
    "print r"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generic definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "class defaultdict(collections.defaultdict):\n",
    "    def __str__(self):\n",
    "        return str(dict(self.items()))\n",
    "    def __repr__(self):\n",
    "        return str(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Ref(object):\n",
    "    def __init__(self, **kwargs):\n",
    "        for key, val in kwargs.iteritems():\n",
    "            setattr(self, 'key', val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extend_dict(base_dict, append_dict): #TODO rename to extend_dict ?\n",
    "    for key in append_dict:\n",
    "        base_dict[key] += append_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Leaf(Listenable):\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "    \n",
    "    def __copy__(self):\n",
    "        return Leaf(self.value)\n",
    "        \n",
    "    def map(self, func):\n",
    "        self.value = func(self.value)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.value)\n",
    "    def __repr__(self):\n",
    "        return repr(self.value)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "old version:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "class Structure(Sequence, Listenable):\n",
    "    \"\"\" implements generic dict-list-combining structure like it is used in pyparsing.ParseResult \"\"\"\n",
    "    \n",
    "    __metaclass__ = LiftableFrom(\"Structure\")\n",
    "    \n",
    "    # Construction\n",
    "    # ------------\n",
    "    \n",
    "    def __init__(self, initializer=None, _list=None, _dict=None):\n",
    "        \"\"\"either initializer or non-empty list is needed\"\"\"\n",
    "        if not _list and not initializer:\n",
    "            raise RuntimeError(\"either _list or initializer is needed\")\n",
    "        self._list = _list or [Leaf(initializer)] # list of sub-Structures\n",
    "        self._dict = _dict or defaultdict(list)\n",
    "        self._name = \"\"\n",
    "        \n",
    "    def __copy__(self):\n",
    "        print \"mycopy\"\n",
    "        # copy other entries?\n",
    "        cp = Structure(\n",
    "            _list=copy(self._list),\n",
    "            _dict=copy(self._dict)\n",
    "        )\n",
    "        cp._update_public_attributes(self) # for in place grouping\n",
    "        return cp\n",
    "    \n",
    "    # Logic\n",
    "    # -----\n",
    "    \n",
    "    def set_name(self, name):\n",
    "#        if self._name: # if not more than one and old name, than delete old name\n",
    "#            # reverse adding of name (TODO hopefully this works is not changed by something)\n",
    "#            dict_entry = self._dict[self._name]\n",
    "#            if len(dict_entry) == 1:\n",
    "#                del self._dict[self._name]\n",
    "#            else:\n",
    "#                dict_entry.pop()\n",
    "        self.pseudogroup = True\n",
    "        self.group_lift_keys_attributes()\n",
    "#       self._name = name\n",
    "        h = hook(self[0])\n",
    "        extend_dict(self._dict, {name: [hook(self[0])]}) #self[0] is old self before grouping,\n",
    "        # hook ensures that everything with key-lifting is korrekt\n",
    "        return self\n",
    "                    \n",
    "    def is_nested(self):\n",
    "        #return isinstance(self._list[0], Structure)\n",
    "        return isinstance(next(iter(self)), Structure)\n",
    "    \n",
    "    def group(self, inplace=True, wrapper=lambda x:x):\n",
    "        if inplace:\n",
    "            self._list = [wrapper(copy(self))]\n",
    "            self._dict = defaultdict(list)\n",
    "            self._name = \"\"\n",
    "            self._delete_public_attributes()\n",
    "            return self       \n",
    "        else:\n",
    "            return Structure(_list=[wrapper(self)]) # no dict, no copying of attributes\n",
    "        \n",
    "    def group_lift_keys(self, inplace=True, wrapper=lambda x:x):\n",
    "        if inplace:\n",
    "            self._list = [wrapper(copy(self))]\n",
    "            self._dict = self._lift_keys(self._dict)\n",
    "            self._name = \"\"\n",
    "            self._delete_public_attributes() # no copying of attributes\n",
    "            return self       \n",
    "        else:\n",
    "            return Structure(_list=[wrapper(self)], _dict=self._lift_keys(self._dict)) # no copying of attributes\n",
    "    \n",
    "    @staticmethod \n",
    "    def _lift_keys(_dict):\n",
    "        return defaultdict(\n",
    "            list,\n",
    "            { k: [l.new_hook() for l in v] # hook everything anew so that separate lists are generated\n",
    "              for k, v in _dict.iteritems()\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    def group_lift_keys_attributes(self, inplace=True, wrapper=lambda x:x):\n",
    "        if inplace:\n",
    "            self._list = [wrapper(copy(self))]\n",
    "            self._dict = self._lift_keys(self._dict)\n",
    "            self._is_set_name = False\n",
    "            return self\n",
    "        else:\n",
    "            cp = Structure(_list=[wrapper(self)], _dict=self._lift_keys(self._dict))\n",
    "            cp.update_public_attributes(self)\n",
    "            return cp\n",
    "                    \n",
    "    def map(self, func, inplace=True):\n",
    "        \"\"\"Structure is a functor =)\"\"\"\n",
    "        if not inplace:\n",
    "            return deepcopy(self).map(func)\n",
    "\n",
    "        #this works as also leaves have .map function and stop recursion\n",
    "        for elem in self:\n",
    "            elem.map(func)\n",
    "    \n",
    "    # general helper methods:\n",
    "    def _update_public_attributes(self, cls):\n",
    "        for attr in dir(cls):\n",
    "            if not attr.startswith(\"_\"):\n",
    "                setattr(self, attr, getattr(cls, attr))\n",
    "\n",
    "    def _update_public_attributes_dict(self, kwargs):\n",
    "        for attr, value in kwargs.iteritems():\n",
    "            if not attr.startswith(\"_\"):\n",
    "                setattr(self, attr, value)\n",
    "        \n",
    "    def _delete_public_attributes(self):\n",
    "        for attr in dir(self):\n",
    "            if not attr.startswith(\"_\"):\n",
    "                delattr(self, attr)\n",
    "    \n",
    "    # general interface methods:\n",
    "    # --------------------------\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if isinstance(index, int):\n",
    "            return self._list[index]\n",
    "        else:\n",
    "            return self._dict[index]\n",
    "#            toreturn = self._dict[index]\n",
    "#            if isinstance(toreturn, dict):\n",
    "#                # [] nesting is for compatibility with standard set_name constructions:\n",
    "#                return [Structure(_list=self._list, _dict=toreturn)]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._list)\n",
    "                    \n",
    "    def keys(self):\n",
    "        return self._dict.keys()\n",
    "        \n",
    "    def __add__(self, other):\n",
    "        base = copy(self)\n",
    "        base += other # (+=) == __iadd__\n",
    "        return base\n",
    "    \n",
    "    def __call__(self, name):\n",
    "        return copy(self).set_name(name)\n",
    "        \n",
    "    def __iadd__(self, other):\n",
    "        \"\"\"\n",
    "        self.list gets extended\n",
    "        self.dict gets extended (always list structures as keys),\n",
    "        self.kwargs get updated (new elements overwrite old once with same name)\n",
    "        \"\"\"\n",
    "        if not isinstance(other, Structure):\n",
    "            raise NotImplemented\n",
    "        self._list += other._list\n",
    "        extend_dict(self._dict, other._dict)\n",
    "        self._name = \"\"\n",
    "        self._update_public_attributes(other)\n",
    "        return self\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self._list)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"(%s, %s)\"%(repr(self._list), repr(self._dict))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def hook(structure):\n",
    "    # this generates a common namespace for a set of classes\n",
    "    hooked = Ref()\n",
    "    def copy_listener(cp):\n",
    "        hooked.ref += cp\n",
    "            \n",
    "    class StructureHooked(Structure):\n",
    "        \"\"\" implements key-lifting \"\"\"\n",
    "\n",
    "        def __initialize__(self, structure):\n",
    "            self.structure = structure\n",
    "            hooked.ref = self\n",
    "            structure.add_listener('__copy__', id(self), copy_listener)\n",
    "\n",
    "        def __copy__(self):\n",
    "            cp = Structure.__copy__(self)\n",
    "            hooked.ref = cp\n",
    "            return cp\n",
    "        \n",
    "        def new_hook(self):\n",
    "            \"\"\"second copy function which also makes a new hooked seed - needed for lifting\"\"\"\n",
    "            return hook(self.structure)\n",
    "\n",
    "    new = copy(structure)\n",
    "    lift(new, StructureHooked, structure=structure)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "old old version:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "class Structure(Sequence, Listenable):\n",
    "    \"\"\" implements generic dict-list-combining structure like it is used in pyparsing.ParseResult \"\"\"\n",
    "    \n",
    "    __metaclass__ = LiftableFrom(\"Structure\")\n",
    "        \n",
    "    def __init__(self, _list=None, _dict=None, initializer=None):\n",
    "        \"\"\"either initializer or non-empty list is needed\"\"\"\n",
    "        if not list or not initializer:\n",
    "            raise RuntimeError(\"either _list or _list-initializer kwargs are needed\")\n",
    "        self._list = _list or [Leaf(initializer)] # list of sub-Structures\n",
    "        self._dict = _dict or defaultdict(list)\n",
    "        self._name = \"\"\n",
    "        \n",
    "    def update_public_attributes(self, cls):\n",
    "        for attr in dir(cls):\n",
    "            if not attr.startswith(\"_\"):\n",
    "                setattr(self, attr, getattr(cls, attr))\n",
    "\n",
    "    def update_public_attributes_dict(self, kwargs):\n",
    "        for attr, value in kwargs.iteritems():\n",
    "            if not attr.startswith(\"_\"):\n",
    "                setattr(self, attr, value)\n",
    "        \n",
    "    def delete_public_attributes(self):\n",
    "        for attr in dir(self):\n",
    "            if not attr.startswith(\"_\"):\n",
    "                delattr(self, attr)\n",
    "    \n",
    "    def __copy__(self):\n",
    "        # copy other entries?\n",
    "        cp = Structure(\n",
    "            _list=copy(self._list),\n",
    "            _dict=copy(self._dict)\n",
    "        )\n",
    "        cp.update_public_attributes(self)\n",
    "        return cp\n",
    "    \n",
    "    def set_name(self, name):\n",
    "        if len(self) > 1:\n",
    "            self.pseudogroup = True\n",
    "            self.group_lift_keys_attributes() # nest if more than one\n",
    "        elif self._name: # if not more than one and old name, than delete old name\n",
    "            # reverse adding of name (TODO hopefully this works is not changed by something)\n",
    "            dict_entry = self._dict[self._name]\n",
    "            if len(dict_entry) == 1:\n",
    "                del self._dict[self._name]\n",
    "            else:\n",
    "                dict_entry.pop()\n",
    "\n",
    "        self._name = name\n",
    "        extend_dict(self._dict, {name: [self[0]]}) #self[0] is old self before grouping\n",
    "        \"\"\"\n",
    "        if not self._dict:\n",
    "            # init dictionary - leafs are always lists\n",
    "            # the nested [] is because pyparsing indeed makes nested [] for listAllMatches=True\n",
    "            self._dict = {name: [self._list]}\n",
    "        elif len(self._dict) == 1:\n",
    "            # this seems to be the behaviour of PyParsing\n",
    "            # it might be useful to rather also check that the overall content\n",
    "            # has not changed, i.e. self.dict.values() == [[self.list]]\n",
    "            # but this is not the case in pyparsing yet\n",
    "            self._dict = {name: self._dict.values()[0]}\n",
    "        else:\n",
    "            h = self._dict\n",
    "            self._dict = {name: [h]} # this is parsed later to give ParseResult like access, nested [] is as for initialization\n",
    "        \"\"\"\n",
    "                    \n",
    "    def is_nested(self):\n",
    "        #return isinstance(self._list[0], Structure)\n",
    "        return isinstance(next(iter(self)), Structure)\n",
    "    \n",
    "    def group(self, inplace=True, wrapper=lambda x:x):\n",
    "        if inplace:\n",
    "            self._list = [wrapper(copy(self))]\n",
    "            self._dict = defaultdict(list)\n",
    "            self._name = \"\"\n",
    "            self.delete_public_attributes()\n",
    "            return self       \n",
    "        else:\n",
    "            return Structure(_list=[wrapper(self)]) # no dict, no copying of attributes\n",
    "        \n",
    "    def group_lift_keys(self, inplace=True, wrapper=lambda x:x):\n",
    "        if inplace:\n",
    "            self._list = [wrapper(copy(self))]\n",
    "            self._dict = copy(self._dict)\n",
    "            self._name = \"\"\n",
    "            self.delete_public_attributes() # no copying of attributes\n",
    "            return self       \n",
    "        else:\n",
    "            return Structure(_list=[wrapper(self)], _dict=copy(self._dict)) # no copying of attributes\n",
    "    \n",
    "    def group_lift_keys_attributes(self, inplace=True, wrapper=lambda x:x):\n",
    "        if inplace:\n",
    "            self._list = [wrapper(copy(self))]\n",
    "            self._dict = copy(self._dict)\n",
    "            self._is_set_name = False\n",
    "            return self\n",
    "        else:\n",
    "            cp = Structure(_list=[wrapper(self)], _dict=copy(self._dict))\n",
    "            cp.update_public_attributes(self)\n",
    "            return cp\n",
    "                    \n",
    "    def map(self, func, inplace=True):\n",
    "        \"\"\"Structure is a functor =)\"\"\"\n",
    "        if not inplace:\n",
    "            return deepcopy(self).map(func)\n",
    "\n",
    "        #this works as also leaves have .map function and stop recursion\n",
    "        for elem in self:\n",
    "            elem.map(func)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if isinstance(index, int):\n",
    "            return self._list[index]\n",
    "        else:\n",
    "            toreturn = self._dict[index]\n",
    "            if isinstance(toreturn, dict):\n",
    "                # [] nesting is for compatibility with standard set_name constructions:\n",
    "                return [Structure(_list=self._list, _dict=toreturn)]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._list)\n",
    "                    \n",
    "    def keys(self):\n",
    "        return self._dict.keys()\n",
    "        \n",
    "    def __add__(self, other):\n",
    "        base = copy(self)\n",
    "        base += other # (+=) == __iadd__\n",
    "        return base\n",
    "    \n",
    "    def __iadd__(self, other):\n",
    "        \"\"\"\n",
    "        self.list gets extended\n",
    "        self.dict gets extended (always list structures as keys),\n",
    "        self.kwargs get updated (new elements overwrite old once with same name)\n",
    "        \"\"\"\n",
    "        if not isinstance(other, Structure):\n",
    "            raise NotImplemented\n",
    "        self._list += other._list\n",
    "        extend_dict(self._dict, other._dict)\n",
    "        self._name = \"\"\n",
    "        self.update_public_attributes(other)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self._list)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"(%s, %s)\"%(repr(self._list), repr(self._dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Structure(Sequence, Listenable):\n",
    "    \"\"\" implements generic dict-list-combining structure like it is used in pyparsing.ParseResult \"\"\"\n",
    "    \n",
    "    __metaclass__ = LiftableFrom(\"Structure\")\n",
    "    \n",
    "    # Construction\n",
    "    # ------------\n",
    "    \n",
    "    def __init__(self, initializer=None, _list=None, _dict=None):\n",
    "        \"\"\"either initializer or non-empty list is needed\"\"\"\n",
    "        if not _list and not initializer:\n",
    "            raise RuntimeError(\"either _list or initializer is needed\")\n",
    "        self._list = _list or [Leaf(initializer)] # list of sub-Structures\n",
    "        self._dict = _dict or defaultdict(list)\n",
    "        self._name = \"\"\n",
    "        \n",
    "    def __copy__(self):\n",
    "        # copy other entries?\n",
    "        cp = Structure(\n",
    "            _list=copy(self._list),\n",
    "            _dict=copy(self._dict)\n",
    "        )\n",
    "        cp._update_public_attributes(self) # for in place grouping\n",
    "        return cp\n",
    "    \n",
    "    # Logic\n",
    "    # -----\n",
    "    \n",
    "    # TODO handle pseudogroups! they should not appear in real listing\n",
    "    \n",
    "    def set_name(self, name):\n",
    "#        TODO replace name feature:\n",
    "#        if self._name: # if not more than one and old name, than delete old name\n",
    "#            # reverse adding of name (TODO hopefully this works is not changed by something)\n",
    "#            dict_entry = self._dict[self._name]\n",
    "#            if len(dict_entry) == 1:\n",
    "#                del self._dict[self._name]\n",
    "#            else:\n",
    "#                dict_entry.pop()\n",
    "        self.group_lift_keys_attributes()\n",
    "        next(iter(self)).pseudogroup = True # adapt old group\n",
    "#       self._name = name\n",
    "        extend_dict(self._dict, {name: [self[0]]}) #self[0] is old self before grouping,\n",
    "        return self\n",
    "                    \n",
    "    def is_nested(self):\n",
    "        #return isinstance(self._list[0], Structure)\n",
    "        return isinstance(next(iter(self)), Structure)\n",
    "    \n",
    "    def group(self, inplace=True, wrapper=lambda x:x):\n",
    "        if inplace:\n",
    "            self._list = [wrapper(copy(self))]\n",
    "            self._dict = defaultdict(list)\n",
    "            self._name = \"\"\n",
    "            self._delete_public_attributes()\n",
    "            return self       \n",
    "        else:\n",
    "            return Structure(_list=[wrapper(self)]) # no dict, no copying of attributes\n",
    "        \n",
    "    def group_lift_keys(self, inplace=True, wrapper=lambda x:x):\n",
    "        if inplace:\n",
    "            lifted = wrapper(copy(self))\n",
    "            lifted.lifted = True\n",
    "            self._list = [lifted]\n",
    "            self._dict = self._lift_keys(lifted._dict)\n",
    "            self._name = \"\"\n",
    "            self._delete_public_attributes() # no copying of attributes\n",
    "            return self       \n",
    "        else:\n",
    "            self.lifted = True\n",
    "            return Structure(_list=[wrapper(self)], _dict=self._lift_keys(self._dict)) # no copying of attributes\n",
    "    \n",
    "    @staticmethod \n",
    "    def _lift_keys(_dict):\n",
    "        return defaultdict(\n",
    "            list,\n",
    "            { k: ['lifted'] for k, v in _dict.iteritems() }\n",
    "        )\n",
    "    \n",
    "    def group_lift_keys_attributes(self, inplace=True, wrapper=lambda x:x):\n",
    "        if inplace:\n",
    "            lifted = wrapper(copy(self))\n",
    "            lifted.lifted = True\n",
    "            self._list = [lifted]\n",
    "            self._dict = self._lift_keys(lifted._dict)\n",
    "            self._name = \"\"\n",
    "            return self\n",
    "        else:\n",
    "            self.lifted = True\n",
    "            cp = Structure(_list=[wrapper(self)], _dict=self._lift_keys(self._dict))\n",
    "            cp.update_public_attributes(self)\n",
    "            return cp\n",
    "                    \n",
    "    def map(self, func, inplace=True):\n",
    "        \"\"\"Structure is a functor =)\"\"\"\n",
    "        if not inplace:\n",
    "            return deepcopy(self).map(func)\n",
    "\n",
    "        #this works as also leaves have .map function and stop recursion\n",
    "        for elem in self:\n",
    "            elem.map(func)\n",
    "        return self\n",
    "    \n",
    "    # general helper methods:\n",
    "    def _update_public_attributes(self, other):\n",
    "        for attr in dir(other):\n",
    "            if not attr.startswith(\"_\") and attr not in dir(self.__class__):\n",
    "                setattr(self, attr, getattr(other, attr))\n",
    "\n",
    "    def _update_public_attributes_dict(self, kwargs):\n",
    "        for attr, value in kwargs.iteritems():\n",
    "            if not attr.startswith(\"_\") and attr not in dir(self.__class__):\n",
    "                setattr(self, attr, value)\n",
    "        \n",
    "    def _delete_public_attributes(self):\n",
    "        for attr in dir(self):\n",
    "            if not attr.startswith(\"_\") and attr not in dir(self.__class__):\n",
    "                delattr(self, attr)\n",
    "    \n",
    "    \n",
    "    # general interface methods:\n",
    "    # --------------------------\n",
    "    \n",
    "    def __iter__(self):\n",
    "        def gen():\n",
    "            for s in self._list:\n",
    "                if hasattr(s, 'pseudogroup'):\n",
    "                    for s2 in iter(s): # yield from in python 3.x\n",
    "                        yield s2\n",
    "                else:\n",
    "                    yield s\n",
    "        return gen()\n",
    "                        \n",
    "    def __getitem__(self, index):\n",
    "        if isinstance(index, int):\n",
    "            return list(iter(self))[index]  #TODO extremely inefficient! (but won't be really needed neither)\n",
    "        else:\n",
    "            # TODO check 'lifted' keyword and in case flatten out all results!\n",
    "            return list(self._iterdictitem(index))\n",
    "    \n",
    "    def _iterdictitem(self, index):\n",
    "        if index in self.keys():\n",
    "            ret = self._dict[index]\n",
    "            for elem in ret:\n",
    "                if elem == 'lifted':\n",
    "                    for s in self._list: #take true underlying structure, not the one with removed pseudogroups\n",
    "                        for i in s._iterdictitem(index):  # yield from in python 3.x\n",
    "                            yield i\n",
    "                else:\n",
    "                    yield elem        \n",
    "                    \n",
    "    def __len__(self):\n",
    "        return len(self._list)\n",
    "                    \n",
    "    def keys(self):\n",
    "        return self._dict.keys()\n",
    "        \n",
    "    def __add__(self, other):\n",
    "        base = copy(self)\n",
    "        base += other # (+=) == __iadd__\n",
    "        return base\n",
    "    \n",
    "    def __call__(self, name):\n",
    "        return copy(self).set_name(name)\n",
    "        \n",
    "    def __iadd__(self, other):\n",
    "        if not isinstance(other, Structure):\n",
    "            raise NotImplemented\n",
    "        self._list += other._list\n",
    "        self._extend_dict(self._dict, other._dict)\n",
    "        self._name = \"\"\n",
    "        self._update_public_attributes(other)\n",
    "        return self\n",
    "    \n",
    "    @staticmethod\n",
    "    def _extend_dict(base_dict, append_dict): #TODO rename to extend_dict ?\n",
    "        \"\"\" extends base_dict by append_dict however keeps only one 'lifted' entry\"\"\"\n",
    "        for key in append_dict:\n",
    "            base = base_dict[key]\n",
    "            base_dict[key] = list(deleteallbutone(base_dict[key] + append_dict[key], 'lifted'))\n",
    "            \n",
    "    def __str__(self):\n",
    "        return \"[\" + \",\".join(str(i) for i in self)+ \"]\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        public_attr ={attr:getattr(self, attr) for attr in dir(self) if not attr.startswith(\"_\") and attr not in dir(self.__class__)}\n",
    "        if public_attr:\n",
    "            return \"(%s, %s, %s)\"%(repr(self._list), repr(self._dict), repr(public_attr))\n",
    "        else:\n",
    "            return \"(%s, %s,)\"%(repr(self._list), repr(self._dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parser specific definitions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# needed?:\n",
    "grouped = r\"\\((?!\\?)\" # matches bracket which is not followed by ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "silently_ignore = []\n",
    "\n",
    "_MAX_INT = sys.maxint\n",
    "\n",
    "begins_suppressed = regex.compile(r\"\\(\\?:\") #TODO rename to begins_silently_grouped ?\n",
    "begins_named = regex.compile(r\"\\(\\?P<([^>]*)>\")\n",
    "#begins_named2 = regex.compile(r\"\\(\\?<([^>]*)>\")\n",
    "begins_grouped = regex.compile(r\"\\(\")\n",
    "ends_grouped = regex.compile(r\"(?r)\\)\") #reversed search feature (?r)    \n",
    "\n",
    "begins_not_silently_grouped = regex.compile(r\"\\((?!\\?)\")\n",
    "\n",
    "def group(pattern):\n",
    "    return \"(%s)\"%(pattern)\n",
    "\n",
    "def ensure_grouping(pattern):\n",
    "    ''' # this does not work in all cases\n",
    "    if not begins_grouped.match(pattern):\n",
    "        pattern = \"(?:\" + pattern  # suppressed group\n",
    "    if not ends_grouped.match(pattern):\n",
    "        pattern += \")\"\n",
    "    return pattern\n",
    "    '''\n",
    "    #simply add another silent grouping:\n",
    "    return \"(?:%s)\" % pattern\n",
    "\n",
    "def decodeflags(flags, flags_sorted_bin = (None, \"i\", \"L\", \"m\", \"s\", \"u\", \"x\")):\n",
    "    return \"\".join(d for d, s in izip(flags_sorted_bin, bin(flags)[-1:1:-1]) if s=='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' dsa (?:sdha) hjka(?:dsa)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "begins_not_silently_grouped.sub(\"(?:\", \" dsa (sdha) hjka(dsa)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ParserElement(Structure):\n",
    "    # __metaclass__ = abc.ABCMeta Liftable is already subtype of abc.ABCMeta, the double metaclass would not work\n",
    "    \n",
    "    '''\n",
    "    def __getattr__(self, attr):\n",
    "        \"\"\"if attr is listed in ``silently_ignore`` will be silently ignored by returning ``self``\n",
    "        else NotImplementedError is raised\"\"\"\n",
    "        if attr in silently_ignore:\n",
    "            def silently_ignored():\n",
    "                return self\n",
    "            return silently_ignored\n",
    "        else:\n",
    "            raise AttributeError(\"Not (yet) implemented\")\n",
    "    '''\n",
    "        \n",
    "    def __call__(self, name, **kwargs):\n",
    "        return copy(self.copy).setResultsName(name, **kwargs)\n",
    "    \n",
    "    def setResultsName(self, name, **kwargs):\n",
    "        self.set_name(name)\n",
    "        self.update_public_attributes_dict(kwargs)\n",
    "        return self # TODO is this the standard behaviour?\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def suppress(self):\n",
    "        \"\"\"Suppresses the output of this C{ParserElement}; useful to keep punctuation from\n",
    "           cluttering up returned output.\n",
    "           \n",
    "           change outer brackets, e.g. (...) or (?P<>...) or (?<>...) to non-capturing (?:...) version\n",
    "        \"\"\"\n",
    "        raise NotImplemented\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def repeat(min=0, max=None):\n",
    "        \"\"\" you can repeat a CombinedToken in a simple regular expression way\n",
    "        if it contains no repeated basic Token\"\"\"\n",
    "        raise NotImplemented()\n",
    "        \n",
    "    def parseString(self, instring, parseAll=False):\n",
    "        \"\"\"Execute the parse expression with the given string.\n",
    "        This is the main interface to the client code, once the complete\n",
    "        expression has been built.\n",
    "\n",
    "        If you want the grammar to require that the entire input string be\n",
    "        successfully parsed, then set C{parseAll} to True (equivalent to ending\n",
    "        the grammar with C{L{StringEnd()}}).\n",
    "\n",
    "        Note: C{parseString} implicitly calls C{expandtabs()} on the input string,\n",
    "        in order to report proper column numbers in parse actions.\n",
    "        If the input string contains tabs and\n",
    "        the grammar uses parse actions that use the C{loc} argument to index into the\n",
    "        string being parsed, you can ensure you have a consistent view of the input\n",
    "        string by:\n",
    "        - calling C{parseWithTabs} on your grammar before calling C{parseString}\n",
    "          (see L{I{parseWithTabs}<parseWithTabs>})\n",
    "        - define your parse action using the full C{(s,loc,toks)} signature, and\n",
    "          reference the input string using the parse action's C{s} argument\n",
    "        - explictly expand the tabs in your input string before calling\n",
    "          C{parseString}\n",
    "\n",
    "        Return ParseResult!\n",
    "        \"\"\"\n",
    "        return (self+StringEnd() if parseAll else self)._parseString(instring)\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def _parseString(self, instring):\n",
    "        raise NotImplemented()\n",
    "\n",
    "    \n",
    "    def scanString(self, instring, maxMatches=_MAX_INT, overlap=False):\n",
    "        \"\"\"not supported: maxMatches\n",
    "        \n",
    "        Scan the input string for expression matches.  Each match will return the\n",
    "        matching tokens, start location, and end location.  May be called with optional\n",
    "        C{maxMatches} argument, to clip scanning after 'n' matches are found.  If\n",
    "        C{overlap} is specified, then overlapping matches will be reported.\n",
    "\n",
    "        Note that the start and end locations are reported relative to the string\n",
    "        being parsed.  See L{I{parseString}<parseString>} for more information on parsing\n",
    "        strings with embedded tabs.\n",
    "        \"\"\"\n",
    "        i = 0\n",
    "        matches = 0\n",
    "        while i < len(instring) and matches < maxMatches:\n",
    "            m = self.parseString(instring[i:])\n",
    "            if m is not None:\n",
    "                yield m\n",
    "                matches += 1\n",
    "                if overlap:\n",
    "                    i += 1\n",
    "                else:\n",
    "                    i += m.end()\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "\n",
    "    def transformString(self, instring):\n",
    "        raise NotImplementedError(\"with regular expressions setParseAction is not supported and thus also not transformString\")\n",
    "        #maybe later by using regex substitution\n",
    "\n",
    "    def searchString(self, instring, maxMatches=_MAX_INT):\n",
    "        \"\"\"Another extension to C{L{scanString}}, simplifying the access to the tokens found\n",
    "           to match the given parse expression.  May be called with optional\n",
    "           C{maxMatches} argument, to clip searching after 'n' matches are found.\n",
    "        \"\"\"\n",
    "        return list(self.scanString(instring))\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        base = copy(self)\n",
    "        base += other # (+=) == __iadd__\n",
    "        return base\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def __iadd__(self, other):\n",
    "        raise NotImplemented()\n",
    "\n",
    "    def __or__(self, other):\n",
    "        base = copy(self)\n",
    "        base |= other # (|=) == __iadd__\n",
    "        return base\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def __ior__(self, other):\n",
    "        raise NotImplemented()\n",
    "        \n",
    "class ParseResult(Structure):\n",
    "    \n",
    "    def __initialize__(self, match):\n",
    "        self._match = match\n",
    "        \n",
    "    def end(self):\n",
    "        \"returns match end for given string\"\n",
    "        return self._match.end()\n",
    "    \n",
    "    def span(self):\n",
    "        \"returns match slice for given string\"\n",
    "        return self._match.span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CombinedToken(ParserElement):\n",
    "    \"\"\" not implemented: Whitespaces \n",
    "    linear combination of Tokens gives still regular regex, therefore this intermediate level\n",
    "    \n",
    "    even combinations of repeated CombinedTokens is still regexable, thus captured under this umbrella\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def new(_pattern):\n",
    "        \"\"\" this is the main single Token Constructor\n",
    "        \n",
    "        Combinations of Tokens can be constructed by using + and |\"\"\"\n",
    "        return CombinedToken(initializer=Count(), _pattern=_pattern) # constructor is given by Liftable Metatype\n",
    "\n",
    "    def __initialize__(self, _pattern=\"\"):\n",
    "        self._pattern = _pattern\n",
    "        self._repeated = False\n",
    "        self._compiled = None\n",
    "    \n",
    "    def __copy__(self):\n",
    "        cp = super(CombinedToken, self).__copy__()\n",
    "        lift(cp, CombinedToken, _pattern=self._pattern)\n",
    "        cp._repeated = self._repeated\n",
    "        cp._compiled = self._compiled\n",
    "        return cp\n",
    "        \n",
    "    @overrides\n",
    "    def group(self, inplace=True, wrapper=None):\n",
    "        s = super(CombinedToken, self).group(inplace, wrapper)\n",
    "        if not inplace: #s is simply structure\n",
    "            # make s a CombinedToken and not a Stucture\n",
    "            lift(s, CombinedToken, _pattern=self._pattern)\n",
    "        return s\n",
    "    \n",
    "    @overrides\n",
    "    def group_lift_keys(self, inplace=True, wrapper=None):\n",
    "        s = super(CombinedToken, self).group_lift_keys(inplace, wrapper)\n",
    "        if not inplace: #s is simply structure\n",
    "            # make s a CombinedToken and not a Stucture\n",
    "            lift(s, CombinedToken, _pattern=self._pattern)\n",
    "        return s\n",
    "    \n",
    "    @overrides\n",
    "    def group_lift_keys_attributes(self, inplace=True, wrapper=None):\n",
    "        s = super(CombinedToken, self).group_lift_keys_attributes(inplace, wrapper)\n",
    "        if not inplace: #s is simply structure\n",
    "            # make s a CombinedToken and not a Stucture\n",
    "            lift(s, CombinedToken, _pattern=self._pattern)\n",
    "        return s\n",
    "    \n",
    "    \n",
    "    def suppress(self):\n",
    "        \"\"\"Suppresses the output of this C{ParserElement}; useful to keep punctuation from\n",
    "           cluttering up returned output.\n",
    "           \n",
    "           change all inner brackets, e.g. (...) or (?P<>...) or (?<>...) to non-capturing (?:...) version\n",
    "           Not reversible!\n",
    "        \"\"\"\n",
    "        self._pattern = begins_not_silently_grouped.sub(\"(?:\", self._pattern)\n",
    "    \n",
    "    def repeat(min=0, max=None):\n",
    "        \"\"\" you can repeat a CombinedToken in a simple regular expression way\n",
    "        if it contains no repeated basic Token\"\"\"\n",
    "        # TODO to ensure subgroup being grouped it seems the best thing to do is just to make another silent grouping around!!\n",
    "        # e.g. r'(eins)(zwei)' also starts and ends with (, ) but it is not properly grouped\n",
    "        \n",
    "        if max is None and min > max:\n",
    "            raise RuntimeError(\"min <= max needed\")\n",
    "        \n",
    "        # no nested repeatings:\n",
    "        if not self._repeated:\n",
    "            # TODO nesting also needed if CombinedToken == SingleToken\n",
    "            self._repeated = True #new nesting - the old list can be ignored as there was no repeating at all\n",
    "            # TODO I think this ensuring is not needed, simply add silent-group (?)\n",
    "            self._pattern = ensure_grouping(self._pattern) \n",
    "\n",
    "            if max is None:\n",
    "                self._pattern = r\"%s{%s,}+\"%(self._pattern, min)\n",
    "            elif min == max:\n",
    "                self._pattern = r\"%s{%s}+\"%(self._pattern, min)\n",
    "            else:\n",
    "                self._pattern = r\"%s{%s,%s}+\"%(self._pattern, min, max)\n",
    "            \n",
    "            self.group_lift_keys(wrapper=Leaf) # new pseudo nesting\n",
    "            self.pseudogroup = True\n",
    "            \n",
    "        else:\n",
    "            # nested repeating is not possible with simple regex\n",
    "            # TODO make ParseEnhance Structure\n",
    "            raise NotImplementedError(\"follows soon\")\n",
    "        \n",
    "    def _parseString(self, instring, inplace=False):\n",
    "        \"\"\"starts matchin at starts of ``instring`` - no search\"\"\"\n",
    "        Count.reset()\n",
    "        \n",
    "        if self._compiled is None:\n",
    "            self._compiled = regex.compile(self._pattern)\n",
    "        \n",
    "        m = self._compiled.match(instring)\n",
    "        if m is None:\n",
    "            return None\n",
    "        # TODO this is only for performance,\n",
    "        # rebuild this internal regex-repeated-structure to valid Structure-structure when parsing\n",
    "        cp = self.map(self._parse_leaf_func(m), inplace=inplace)\n",
    "        relift(cp, ParseResult, match=m)\n",
    "        return cp\n",
    "        \n",
    "    @staticmethod\n",
    "    def _parse_leaf_func(match):\n",
    "        # TODO maybe abstract this out into ParserElement ? see how ParseElementEnhance will work\n",
    "        def func(value):\n",
    "            # TODO: _repeated check seems not necessary if there is only one case that CombinedTokens can be leaves\n",
    "            if isinstance(value, CombinedToken) and value._repeated:\n",
    "                # evaluate all groups - ATTENTION now value is directly available\n",
    "                value.map(lambda group: group.value)\n",
    "\n",
    "                def iter_all_captures(elem, match):\n",
    "                    for i in it.count(0):\n",
    "                        try:\n",
    "                            yield elem.map(\n",
    "                                func=lambda val: match.captures(val)[i],\n",
    "                                inplace=False\n",
    "                            )\n",
    "                        except IndexError:\n",
    "                            break\n",
    "\n",
    "                return list(self.iter_all_captures(elem, match))\n",
    "            \n",
    "            elif isinstance(value, Count):\n",
    "                return match.group(value.value)\n",
    "            \n",
    "        return func\n",
    "    \n",
    "    def __iadd__(self, other):\n",
    "        if isinstance(other, CombinedToken):\n",
    "            Structure.__iadd__(self, other)\n",
    "            self._pattern += other._pattern\n",
    "            self._repeated |= other._repeated\n",
    "            self._compiled = None\n",
    "        else:\n",
    "            raise NotImplemented\n",
    "        return self\n",
    "    \n",
    "    def __ior__(self, other):\n",
    "        if isinstance(other, CombinedToken):\n",
    "            Structure.__iadd__(self, other) # maybe better Structure.__iadd_(self, other) ? seems more readable and saver against mixins\n",
    "            # or super(CombinedToken, self).__iadd__(other)\n",
    "            self._pattern += \"|\" + other._pattern\n",
    "            self._repeated |= other._repeated\n",
    "            self._compiled = None\n",
    "        else:\n",
    "            raise NotImplemented\n",
    "        return self\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"(r'%s', %s)\" % (self._pattern, Structure.__str__(self))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"(r'%s', %s)\" % (self._pattern, Structure.__repr__(self))\n",
    "\n",
    "\n",
    "def Token(pattern):\n",
    "    return CombinedToken.new(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ParseElementEnhance(ParserElement):\n",
    "    \"\"\"a more complex regex-output could replace all this, however it seems that currently this is still needed\"\"\"\n",
    "    def repeat(self, min, max):\n",
    "        if max is None and min > max:\n",
    "            raise RuntimeError(\"min <= max needed\")\n",
    "        self.repeat = (min, max) # gets nested as public attribute\n",
    "        self.group_lift_keys(wrapper=Leaf) # nests\n",
    "\n",
    "    def _parseString(self, instring, inplace=False):\n",
    "        \"\"\"starts matching at starts of ``instring`` - no search\"\"\"\n",
    "        cp = self.map(self._parse_leaf_func(instring), inplace=inplace)\n",
    "        relift(cp, ParseResult, match=m) #TODO get match functionality ?? .end() for most ??\n",
    "        return cp\n",
    "        \n",
    "    @staticmethod\n",
    "    def _parse_leaf_func(instring):\n",
    "        ref = Ref(str=instring)\n",
    "        def func(value):\n",
    "            # TODO: _repeated check seems not necessary if there is only one case that CombinedTokens can be leaves\n",
    "            if isinstance(value, CombinedToken):\n",
    "                parseresult = value._parseString(ref.str)\n",
    "                ref.str = ref.str[parseresult.end():] # TODO may include backtracking option in this reference string\n",
    "                return delift(parseresult, Structure)\n",
    "                \n",
    "            elif isinstance(value, ParseElementEnhance):\n",
    "                # should always be a repeated element\n",
    "                if hasattr(value, 'repeated'):\n",
    "                    min, max = value.repeated\n",
    "                    if max is None:\n",
    "                        count = it.count(min)\n",
    "                    else:\n",
    "                        count = range(min, max+1)\n",
    "                        \n",
    "                    def doall():\n",
    "                        for _ in range(min):\n",
    "                            # errors here are realy errors and should elicit backtracking\n",
    "                            # can be either CombinedToken or ParseElementEnhance\n",
    "                            parseresult = value._parseString(ref.str)\n",
    "                            ref.str = ref.str[parseresult.end():]\n",
    "                            yield parseresult\n",
    "                        for i in count:\n",
    "                            #errors here can be silently ignored:\n",
    "                            try:\n",
    "                                parseresult = value._parseString(ref.str)\n",
    "                                ref.str = ref.str[parseresult.end():]\n",
    "                                yield parseresult\n",
    "                            except: #TODO add specific errors\n",
    "                                break\n",
    "                    return list(doall())\n",
    "                else:\n",
    "                    raise RuntimeError(\"should this be the case?\")\n",
    "            # the following should not happen:\n",
    "            #elif isinstance(value, Count):\n",
    "            #    return match.group(value.value)\n",
    "            \n",
    "        return func    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Group(expr):\n",
    "    return expr.group(inplace=False)\n",
    "\n",
    "def GroupLiftKeys(expr):\n",
    "    return expr.group_lift_keys(inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Suppress(expr):\n",
    "    expr.suppress()\n",
    "    return expr\n",
    "\n",
    "def And(iterable):\n",
    "    \"\"\"in place version\"\"\"\n",
    "    try:\n",
    "        gen = iter(iterable)\n",
    "        base = next(gen) + next(gen) # once (+) to have a new element\n",
    "        for expr in gen:\n",
    "            base += expr\n",
    "        return base\n",
    "    except StopIteration: # only one element\n",
    "        return next(iter(iterable))\n",
    "\n",
    "\n",
    "def MatchFirst(iterable):\n",
    "    \"\"\"in place version\"\"\"\n",
    "    try:\n",
    "        gen = iter(iterable)\n",
    "        base = next(gen) | next(gen) # once (|) to have a new element\n",
    "        for expr in gen:\n",
    "            base |= expr\n",
    "        return base\n",
    "    except StopIteration: # only one element\n",
    "        return next(iter(iterable))\n",
    "#Or __xor__ and Each __and__ are missing - takes more time to implement\n",
    "\n",
    "\n",
    "def Optional(expr):\n",
    "    cp = copy(expr)\n",
    "    cp._pattern = r\"%s?\"%(ensure_grouping(cp._pattern))\n",
    "    return cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Regex(pattern, flags=0):\n",
    "    \"\"\"Grouped by default. flags are locally scoped and will only effect the supplied pattern, nothing more\"\"\"\n",
    "    if flags:\n",
    "        str_flags = decodeflags(flags)\n",
    "        pattern = r\"(?%s:%s)\"%(str_flags, pattern)\n",
    "    return Token(group(pattern))\n",
    "\n",
    "\n",
    "def Word(initChars, bodyChars=None, min=1, max=0, exact=0, excludeChars=None):\n",
    "    \"\"\"Grouped by default. not implemented kwargs: asKeyword \"\"\"\n",
    "    \n",
    "    if max != 0 and min > max:\n",
    "        raise RuntimeError(\"min <= max needed\")\n",
    "\n",
    "    if excludeChars:\n",
    "        initChars = initChars + \"--\" + excludeChars\n",
    "        if bodyChars:\n",
    "            bodyChars = bodyChars + \"--\" + excludeChars\n",
    "\n",
    "    if exact == 1 or max == 1:\n",
    "        pattern = r\"[%s]{1}\"%(initChars)    \n",
    "    elif exact > 1:\n",
    "        if bodyChars:\n",
    "            pattern = r\"[%s]{1}[%s]{%s}\"%(initChars, bodyChars, exact-1)\n",
    "        else:\n",
    "            pattern = r\"[%s]{%s}\"%(initChars, exact)\n",
    "    elif max > 1:\n",
    "        if bodyChars:\n",
    "            pattern = r\"[%s]{1}[%s]{%s,%s}\"%(initChars, bodyChars, __builtin__.max(min-1,0), max-1)\n",
    "        else:\n",
    "            pattern = r\"[%s]{%s,%s}\"%(initChars, min, max)\n",
    "    else: # arbitrary upper bound\n",
    "        if bodyChars:\n",
    "            pattern = r\"[%s]{1}[%s]{%s,}\"%(initChars, bodyChars, __builtin__.max(min-1,0))\n",
    "        else:\n",
    "            pattern = r\"[%s]{%s,}\"%(initChars, min)\n",
    "\n",
    "    # group by default:\n",
    "    return Token(group(pattern))\n",
    "\n",
    "        \n",
    "def SkipTo(self, expr, include=False):\n",
    "    \"\"\"Grouped by default. not supported: ignore=None, failOn=None.\n",
    "    \n",
    "    Token for skipping over all undefined text until the matched expression is found.\n",
    "    If C{include} is set to true, the matched expression is also parsed (the skipped text\n",
    "    and matched expression are returned as a 2-element list).  The C{ignore}\n",
    "    argument is used to define grammars (typically quoted strings and comments) that\n",
    "    might contain false matches.\n",
    "    \"\"\"\n",
    "    pattern = r\"(?:.(?!%s))*.\"%(expr)\n",
    "    if include:\n",
    "        pattern += expr\n",
    "    # group by default:\n",
    "    return Token(group(self.pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OneOrMore(self, expr):\n",
    "    \"\"\"grouped by default\"\"\"\n",
    "#     pattern = r\"%s+\"%(ensure_grouping(expr.pattern))\n",
    "#     return ParserElement(group(self.pattern))\n",
    "    return Repeat(expr, min=1)\n",
    "        \n",
    "def ZeroOrMore(self, expr):\n",
    "    \"\"\"grouped by default\"\"\"\n",
    "#     pattern = r\"%s*\"%(ensure_grouping(expr.pattern))\n",
    "#     return ParserElement(group(self.pattern))\n",
    "    return Repeat(expr)\n",
    "\n",
    "def Repeat(self, expr, min=0, max=None):\n",
    "    return expr.repeat(min=min, max=max) #TODO will throw not implemented error for nested CombinedTokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def StringStart():\n",
    "    \"\"\"matches beginning of the text\"\"\"\n",
    "    return Token(r\"^\")\n",
    "\n",
    "def StringEnd():\n",
    "    \"\"\"matches the end of the text\"\"\"\n",
    "    return Token(r\"$\")\n",
    "\n",
    "def LineStart():\n",
    "    \"\"\"matches beginning of a line (lines delimited by \\n characters)\"\"\"\n",
    "    return Regex(r\"^\", regex.MULTILINE)\n",
    "\n",
    "def LineEnd():\n",
    "    \"\"\"matches the end of a line\"\"\"\n",
    "    return Regex(r\"$\", regex.MULTILINE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
