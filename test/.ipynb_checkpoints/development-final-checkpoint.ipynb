{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.debugger import Tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyparsing as pp\n",
    "import regex\n",
    "import sys\n",
    "from itertools import izip\n",
    "import itertools as it\n",
    "from copy import copy, deepcopy\n",
    "from collections import Sequence\n",
    "import abc\n",
    "import operator as op\n",
    "from collections import defaultdict, namedtuple\n",
    "from overrides import overrides\n",
    "import inspect\n",
    "from contextlib import contextmanager\n",
    "from functools import partial\n",
    "from numpy import inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mymeta import lift, delift, relift, LiftableFrom\n",
    "from mymixin import Listenable\n",
    "from mygenerators import deleteallbutone\n",
    "from myobjects import Count\n",
    "from mywrappers import defaultdict\n",
    "import helpers_regex as hre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from wrapt import ObjectProxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "range = xrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex Implementation of Pyparsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generic definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Leaf(object):\n",
    "    \"\"\" this class just denotes a Leaf of a (nested) Structure\n",
    "    \n",
    "    these are the base elements for the functor (map) ability\n",
    "    \n",
    "    further Leafs with pseudorgroup structure as element will be flatten out\n",
    "    in the final Structure and thus they are not visible at all\n",
    "    \"\"\"\n",
    "    def __init__(self, leaf):\n",
    "        self.leaf = leaf\n",
    "        \n",
    "    def map(self, func):\n",
    "        self.leaf = func(self.leaf)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.leaf)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return repr(self.leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Structure(Sequence):\n",
    "    \"\"\" implements generic dict-list-combining structure like it is used in pyparsing.ParseResult \"\"\"\n",
    "    \n",
    "    # Construction\n",
    "    # ------------\n",
    "    \n",
    "    def __init__(self, initializer=None, _list=None, _dict=None):\n",
    "        \"\"\"either initializer or non-empty list is needed\"\"\"\n",
    "        if not _list and not initializer:\n",
    "            raise RuntimeError(\"either _list or initializer is needed\")\n",
    "        self._list = _list or [Leaf(initializer)] # list of sub-Structures\n",
    "        self._dict = _dict or defaultdict(list)\n",
    "        self.pseudo = False\n",
    "        self.liftedkeys = False\n",
    "\n",
    "    # Logic\n",
    "    # -----\n",
    "    \n",
    "    def set_name(self, name):\n",
    "        self.group(pseudo=True, liftkeys=True)\n",
    "        #self._list[0] is old self before grouping, mind this is equal to self[0], however latter access is much slower\n",
    "        self._extend_dict({name: [self._list[0]]})\n",
    "        return self\n",
    "\n",
    "    def group(self, wrapper=lambda x:x, pseudo=False, liftkeys=False):\n",
    "        \"\"\" CAUTION: changes self inplace\n",
    "        deepcopy before if you like to have a new object \"\"\"\n",
    "        self.pseudo = pseudo\n",
    "        self.liftedkeys = liftkeys\n",
    "        \n",
    "        cp = copy(self)\n",
    "        Structure.__init__(self,\n",
    "            _list = [wrapper(cp)],\n",
    "            _dict = self._lift_keys(cp._dict) if liftkeys else defaultdict(list)\n",
    "        )\n",
    "        return self       \n",
    "    \n",
    "    @staticmethod \n",
    "    def _lift_keys(_dict):\n",
    "        return defaultdict(\n",
    "            list,\n",
    "            { k: ['lifted'] for k, v in _dict.iteritems() }\n",
    "        )\n",
    "                    \n",
    "    def map(self, func):\n",
    "        \"\"\"Structure is a functor =), everything is inplace,\n",
    "        \n",
    "        deepcopy before if you want to have a new object\"\"\"\n",
    "        #this works as also leaves have .map function and stop recursion\n",
    "        for elem in self.iter_leave_leaves():\n",
    "            elem.map(func)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    # general interface methods:\n",
    "    # --------------------------\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for s in self._list:\n",
    "            if isinstance(s, Structure):\n",
    "                if s.pseudo:\n",
    "                    for s2 in iter(s): # yield from in python 3.x\n",
    "                        yield s2\n",
    "                else:\n",
    "                    yield s\n",
    "            # flatten out Leaves:\n",
    "            elif isinstance(s, Leaf):\n",
    "                if isinstance(s.leaf, Structure) and s.leaf.pseudo:\n",
    "                    for s2 in iter(s.leaf): # yield from in python 3.x\n",
    "                        yield s2\n",
    "                else:\n",
    "                    yield s.leaf\n",
    "\n",
    "    def iter_leave_leaves(self):\n",
    "        for s in self._list:\n",
    "            if isinstance(s, Structure) and s.pseudo:\n",
    "                for s2 in iter(s): # yield from in python 3.x\n",
    "                    yield s2\n",
    "            else:\n",
    "                yield s\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if isinstance(index, int):\n",
    "            return list(iter(self))[index]  #TODO extremely inefficient! (but won't be really needed neither)\n",
    "        else:\n",
    "            return list(self._dictitem_gen(index))\n",
    "    \n",
    "    def _dictitem_gen(self, index):\n",
    "        \"\"\" checks for 'lifted' keys and in case flattens out all results \"\"\"\n",
    "        if index in self.keys():\n",
    "            ret = self._dict[index]\n",
    "            for elem in ret:\n",
    "                if elem == 'lifted':\n",
    "                    # now we use true underlying structure (ignoreing pseudostructures), is this \n",
    "                    # TODO: or use sefl._list directly?\n",
    "                    for s in self:\n",
    "                        if s.liftedkeys:\n",
    "                            # yield from in python 3.x:\n",
    "                            for i in s._dictitem_gen(index):\n",
    "                                yield i\n",
    "                else:\n",
    "                    yield elem        \n",
    "                    \n",
    "    def __len__(self):\n",
    "        return len(self._list)\n",
    "                    \n",
    "    def keys(self):\n",
    "        return self._dict.keys()\n",
    "        \n",
    "    def __add__(self, other):\n",
    "        base = deepcopy(self)\n",
    "        base += other # (+=) == __iadd__\n",
    "        return base\n",
    "    \n",
    "    def __call__(self, name):\n",
    "        return copy(self).set_name(name)\n",
    "        \n",
    "    def __iadd__(self, other):\n",
    "        if not isinstance(other, Structure):\n",
    "            raise NotImplemented\n",
    "        self._list += other._list\n",
    "        self._extend_dict(other._dict)\n",
    "        return self\n",
    "    \n",
    "    def _extend_dict(self, other_dict):\n",
    "        \"\"\" extends self._dict by other_dict however keeps only one 'lifted' entry\"\"\"\n",
    "        for key in other_dict:\n",
    "            self._dict[key] = list(deleteallbutone('lifted',\n",
    "                self._dict[key] + other_dict[key]\n",
    "            ))\n",
    "            \n",
    "    def __str__(self):\n",
    "        return \"[\" + \",\".join(str(i) for i in self)+ \"]\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        public_attr ={attr:getattr(self, attr) for attr in dir(self) if not attr.startswith(\"_\") and attr not in dir(self.__class__)}\n",
    "        if public_attr:\n",
    "            return \"(%s, %s, %s)\"%(repr(self._list), repr(self._dict), repr(public_attr))\n",
    "        else:\n",
    "            return \"(%s, %s,)\"%(repr(self._list), repr(self._dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recursive_structure_delift(structure, base_class=Structure):\n",
    "    \"\"\" more complex delift for structure types, as the structure type itself is usually nested \"\"\"\n",
    "    structure.__class__ = base_class\n",
    "    for s in structure._list:\n",
    "        if isinstance(s, Structure):\n",
    "            recursive_structure_delift(s, base_class)\n",
    "        elif isinstance(s, Leaf) and isinstance(s.leaf, Structure):\n",
    "            recursive_structure_delift(s.leaf, base_class)\n",
    "    return structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parser specific definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "silently_ignore = []\n",
    "_MAX_INT = sys.maxint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ParserElementType(Structure):\n",
    "    \"\"\" abstract class capturing the interface of an arbitrary ParserElement of pyparsing \"\"\"\n",
    "    __metaclass__ = abc.ABCMeta\n",
    "        \n",
    "    def __call__(self, name, **kwargs):\n",
    "        return copy(self.copy).setResultsName(name, **kwargs)\n",
    "    \n",
    "    def setResultsName(self, name, **kwargs):\n",
    "        self.set_name(name)\n",
    "        self.update_public_attributes_dict(kwargs)\n",
    "        return self # TODO is this the standard behaviour?\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def suppress(self):\n",
    "        \"\"\"Suppresses the output of this C{ParserElement}; useful to keep punctuation from\n",
    "           cluttering up returned output.\n",
    "           \n",
    "           change outer brackets, e.g. (...) or (?P<>...) or (?<>...) to non-capturing (?:...) version\n",
    "        \"\"\"\n",
    "        raise NotImplemented\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def repeat(self, min=0, max=None):\n",
    "        \"\"\" repititions is the main structural addition on top of the Structure-type \"\"\"\n",
    "        raise NotImplemented()\n",
    "        \n",
    "    def parseString(self, instring, parseAll=False):\n",
    "        \"\"\"Execute the parse expression with the given string.\n",
    "        This is the main interface to the client code, once the complete\n",
    "        expression has been built.\n",
    "\n",
    "        If you want the grammar to require that the entire input string be\n",
    "        successfully parsed, then set C{parseAll} to True (equivalent to ending\n",
    "        the grammar with C{L{StringEnd()}}).\n",
    "\n",
    "        Note: C{parseString} implicitly calls C{expandtabs()} on the input string,\n",
    "        in order to report proper column numbers in parse actions.\n",
    "        If the input string contains tabs and\n",
    "        the grammar uses parse actions that use the C{loc} argument to index into the\n",
    "        string being parsed, you can ensure you have a consistent view of the input\n",
    "        string by:\n",
    "        - calling C{parseWithTabs} on your grammar before calling C{parseString}\n",
    "          (see L{I{parseWithTabs}<parseWithTabs>})\n",
    "        - define your parse action using the full C{(s,loc,toks)} signature, and\n",
    "          reference the input string using the parse action's C{s} argument\n",
    "        - explictly expand the tabs in your input string before calling\n",
    "          C{parseString}\n",
    "\n",
    "        Return ParseResult!\n",
    "        \"\"\"\n",
    "        return (self+StringEnd() if parseAll else self)._parseString(instring)\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def _parseString(self, instring):\n",
    "        raise NotImplemented()\n",
    "\n",
    "    \n",
    "    def scanString(self, instring, maxMatches=_MAX_INT, overlap=False):\n",
    "        \"\"\"not supported: maxMatches\n",
    "        \n",
    "        Scan the input string for expression matches.  Each match will return the\n",
    "        matching tokens, start location, and end location.  May be called with optional\n",
    "        C{maxMatches} argument, to clip scanning after 'n' matches are found.  If\n",
    "        C{overlap} is specified, then overlapping matches will be reported.\n",
    "\n",
    "        Note that the start and end locations are reported relative to the string\n",
    "        being parsed.  See L{I{parseString}<parseString>} for more information on parsing\n",
    "        strings with embedded tabs.\n",
    "        \"\"\"\n",
    "        i = 0\n",
    "        matches = 0\n",
    "        while i < len(instring) and matches < maxMatches:\n",
    "            m = self.parseString(instring[i:])\n",
    "            if m is not None:\n",
    "                yield m\n",
    "                matches += 1\n",
    "                if overlap:\n",
    "                    i += 1\n",
    "                else:\n",
    "                    i += m.end()\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "\n",
    "    def transformString(self, instring):\n",
    "        raise NotImplementedError(\"with regular expressions setParseAction is not supported and thus also not transformString\")\n",
    "        #maybe later by using regex substitution\n",
    "\n",
    "    def searchString(self, instring, maxMatches=_MAX_INT):\n",
    "        \"\"\"Another extension to C{L{scanString}}, simplifying the access to the tokens found\n",
    "           to match the given parse expression.  May be called with optional\n",
    "           C{maxMatches} argument, to clip searching after 'n' matches are found.\n",
    "        \"\"\"\n",
    "        return list(self.scanString(instring))\n",
    "    \n",
    "    # add, iadd already defined in Structure\n",
    "            \n",
    "    def __or__(self, other):\n",
    "        base = deepcopy(self)\n",
    "        base |= other # (|=) == __iadd__\n",
    "        return base\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def __ior__(self, other):\n",
    "        raise NotImplemented()\n",
    "        \n",
    "\n",
    "class ParseResult(ObjectProxy):\n",
    "    \"\"\" class capturing interface of return type of pyparsing (and more needed methods) \"\"\"\n",
    "    \n",
    "    # class-level default value for flattening\n",
    "    FLATTEN_SINGLETONS = False\n",
    "    EMPTY_DEFAULT = \"EMPTYLIST\" #this stands for [], however as [] is mutable, its no good idea to make it the default\n",
    "    \n",
    "    def __init__(self, structure, span, flatten_singletons=None, empty_default=\"EMPTYLIST\"):\n",
    "        # proxy the complete structure element:\n",
    "        super(ParseResult, self).__init__(structure)\n",
    "        \n",
    "        # transform it slightly given the additional parameters:\n",
    "        # (map is a function Structure already, as the Proxy was initialized)\n",
    "        if (flatten_singletons is None and ParseResult.FLATTEN_SINGLETONS) or flatten_singletons:\n",
    "            self.map(ParseResult.flatten_singletons)\n",
    "        \n",
    "        if empty_default != \"EMPTYLIST\":\n",
    "            self.map(self.func_change_default(empty_default))\n",
    "        elif ParseResult.EMPTY_DEFAULT != \"EMPTYLIST\":\n",
    "            self.map(self.func_change_default(ParseResult.EMPTY_DEFAULT))\n",
    "            \n",
    "        # general information over ParseResult:\n",
    "        self.span = span\n",
    "        \n",
    "    def end(self):\n",
    "        \"returns match end for given string\"\n",
    "        return self.span[1]\n",
    "    \n",
    "    def span(self):\n",
    "        \"returns (match begin, match end) for given string\"\n",
    "        return self.span\n",
    "    \n",
    "    @staticmethod\n",
    "    def func_change_default(empty_default):\n",
    "        def change_default(leaf):\n",
    "            if leaf == []: # this is the standard empty value\n",
    "                return empty_default\n",
    "            \n",
    "            # recursive call for recursive leaves:\n",
    "            elif isinstance(leaf, Structure):\n",
    "                leaf.map(change_default)\n",
    "            \n",
    "            # in every case default to return leaf\n",
    "            return leaf\n",
    "        return change_default\n",
    "        \n",
    "    @staticmethod\n",
    "    def flatten_singletons(leaf):\n",
    "        \"\"\" for this to work, the leafs must already be mapped to lists\n",
    "        e.g. by using ParserElement._func_parse_leaf \"\"\"\n",
    "        # recursive call for recursive leaves:\n",
    "        if isinstance(leaf, Structure):\n",
    "            leaf.map(ParseResult.flatten_singletons)\n",
    "            \n",
    "        if len(leaf) == 1:\n",
    "            return leaf[0]\n",
    "        return leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ParserElement(ParserElementType):\n",
    "    \"\"\"   \n",
    "    we can immitate arbitrarily complex formula directly by a single regex-string\n",
    "    the output gets restructured (in linear time) to fulfil ParserElement/Structure interface\n",
    "    \n",
    "    not implemented: whitespaces support\n",
    "    \"\"\"\n",
    "    \n",
    "    #: repeated substructure (just a tuple)\n",
    "    Repeated = namedtuple(\"Repeated\", [\"count\", \"struct\"])\n",
    "    MatchedGroup = namedtuple(\"Group\", [\"ends\", \"captures\"])\n",
    "    \n",
    "    # CONSTRUCTION\n",
    "    # ============\n",
    "\n",
    "    def __init__(self, pattern=\"\"):\n",
    "        super(ParserElement, self).__init__(initializer=Count())\n",
    "        self.pattern = pattern\n",
    "        self._compiled = None\n",
    "    \n",
    "    # LOGIC\n",
    "    # =====\n",
    "    \n",
    "    @overrides # TODO does this work - new parameter silent\n",
    "    def group(self, wrapper=lambda x:x, pseudo=False, liftkeys=False, silent=None):\n",
    "        # this is inplace:\n",
    "        super(ParserElement, self).group(wrapper, pseudo=pseudo, liftkeys=liftkeys)\n",
    "        # normal grouping is done by Structure type,\n",
    "        # but silent groups are nevertheless needed for correct regex semantics:\n",
    "        if silent is None:\n",
    "            pass # keep old self.pattern\n",
    "        elif silent:\n",
    "            self.pattern = hre.silent_group(self.pattern)\n",
    "        else:\n",
    "            self.pattern = hre.group(self.pattern)\n",
    "        return self\n",
    "    \n",
    "    def suppress(self):\n",
    "        \"\"\"Suppresses the output of this C{ParserElement}; useful to keep punctuation from\n",
    "           cluttering up returned output.\n",
    "           \n",
    "           change all inner brackets, e.g. (...) or (?P<>...) or (?<>...) to non-capturing (?:...) version\n",
    "           \n",
    "           CAUTION: NOT REVERSIBLE!\n",
    "        \"\"\"\n",
    "        self.pattern = hre.begins_not_silently_grouped.sub(\"(?:\", self.pattern)\n",
    "    \n",
    "    def repeat(self, min=0, max=inf):\n",
    "        \"\"\" repeat on arbitrary ParserElement \"\"\"\n",
    "        if min > max:\n",
    "            raise RuntimeError(\"min <= max needed\")\n",
    "        # if not singleton, then add extra layer for repition:\n",
    "        if not hre.singleton_group.match(self.pattern):\n",
    "            # the grouping is done by wrapping into a Leaf,\n",
    "            # so that we can construct a map function which does all restructuring of the regex output\n",
    "            self.group(\n",
    "                wrapper = lambda struct: Leaf(self.Repeated(Count(), struct)),\n",
    "                pseudo = True,\n",
    "                liftkeys = True,\n",
    "                silent = False,\n",
    "            )\n",
    "        if max is inf:\n",
    "            self.pattern = r\"%s{%s,}+\"   % (self.pattern, min)\n",
    "        elif min == max:\n",
    "            self.pattern = r\"%s{%s}+\"    % (self.pattern, min)\n",
    "        else:\n",
    "            self.pattern = r\"%s{%s,%s}+\" % (self.pattern, min, max)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _transform_match_gen(match):\n",
    "        try:\n",
    "            for i in it.count(1):\n",
    "                yield ParserElement.MatchedGroup(match.ends(i), match.captures(i))\n",
    "        except IndexError:\n",
    "            pass\n",
    "    \n",
    "    def _parseString(self, instring):\n",
    "        \"\"\"starts matchin at starts of ``instring`` - no search\n",
    "        \n",
    "        this is copying everything beforehand\"\"\"\n",
    "        \n",
    "        if self._compiled is None:\n",
    "            self._compiled = regex.compile(self.pattern)\n",
    "        \n",
    "        m = self._compiled.match(instring)\n",
    "        if m is None:\n",
    "            return None\n",
    "        \n",
    "        mymatch = list(self._transform_match_gen(m))\n",
    "        \n",
    "        Count.reset()\n",
    "        cp = deepcopy(self)\n",
    "        cp.map(self._recursive_evalcount)\n",
    "        cp.map(self._func_parse_leaf(mymatch))\n",
    "        #getting default structure str, repr interface (also for nested elements):\n",
    "        recursive_structure_delift(cp)\n",
    "        return ParseResult(cp, span=m.span())\n",
    "    \n",
    "    @staticmethod\n",
    "    def _recursive_evalcount(leaf):\n",
    "        \"\"\" evaluates all Count instances so that they refer to fixed group\"\"\"\n",
    "        if isinstance(leaf, ParserElement.Repeated):\n",
    "            leaf.count.eval()\n",
    "            leaf.struct.map(ParserElement._recursive_evalcount)\n",
    "        elif isinstance(leaf, Count):\n",
    "            leaf.eval()\n",
    "        return leaf\n",
    "    \n",
    "    @staticmethod\n",
    "    def _func_parse_leaf(match):\n",
    "        \"\"\"\n",
    "        CAUTION: for this map to work correctly,\n",
    "        every Count instance must be evaluated already recursively!\n",
    "        \n",
    "        i.e. first map ParserElement._recursive_evalcount\n",
    "        \"\"\"\n",
    "        \n",
    "        def recursive_parse(leaf, maxend=inf):\n",
    "            # recursive case:\n",
    "            if isinstance(leaf, ParserElement.Repeated):\n",
    "                def gen():\n",
    "                    for i, end in enumerate(match[leaf.count.value].ends):\n",
    "                        if end > maxend:\n",
    "                            del match[leaf.count.value].ends[:i] #delete everything parsed so far\n",
    "                            # captures are of no interest at all of these Repeated elements\n",
    "                            # so no need to delete them\n",
    "                            break\n",
    "                        yield deepcopy(leaf.struct).map(partial(recursive_parse, maxend=end))\n",
    "            \n",
    "                # returns structure which is labeld pseudo by initial repeat method\n",
    "                return reduce(op.add, gen())\n",
    "            \n",
    "            # base case:\n",
    "            elif isinstance(leaf, Count):\n",
    "                i = -1\n",
    "                for i, end in enumerate(match[leaf.value].ends):\n",
    "                    if end > maxend:\n",
    "                        # i is now the final valid index+1\n",
    "                        break\n",
    "                else:\n",
    "                    # no break, i.e. we currently miss the last one, OR empty loop\n",
    "                    i += 1 # if nothing was done, i=0 now, giving empty list and no deletes\n",
    "                \n",
    "                ret = match[leaf.value].captures[:i]\n",
    "                # delete everything parsed so far (both captures end ends!):\n",
    "                del match[leaf.value].captures[:i]\n",
    "                del match[leaf.value].ends[:i]\n",
    "                return ret\n",
    "            \n",
    "        return recursive_parse\n",
    "    \n",
    "    def __iadd__(self, other):\n",
    "        if isinstance(other, basestring):\n",
    "            other = Token(other)\n",
    "        \n",
    "        Structure.__iadd__(self, other)\n",
    "        self.pattern += other.pattern\n",
    "        self._compiled = None\n",
    "        return self\n",
    "    \n",
    "    def __radd__(self, other):\n",
    "        if isinstance(other, basestring):\n",
    "            other = Token(other)\n",
    "        other += self\n",
    "        return other\n",
    "        \n",
    "    def __ior__(self, other):\n",
    "        if isinstance(other, basestring):\n",
    "            other = Token(other)\n",
    "        \n",
    "        Structure.__iadd__(self, other)\n",
    "        self.pattern += \"|\" + other.pattern\n",
    "        self._compiled = None\n",
    "        return self\n",
    "    \n",
    "    def __ror__(self, other):\n",
    "        if isinstance(other, basestring):\n",
    "            other = Token(other)\n",
    "        other |= self\n",
    "        return other\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"(r'%s', %s)\" % (self.pattern, Structure.__str__(self))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"(r'%s', %s)\" % (self.pattern, Structure.__repr__(self))\n",
    "\n",
    "\n",
    "def Token(pattern):\n",
    "    return ParserElement(pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyparsing-like Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Regex(pattern, flags=0):\n",
    "    \"\"\"Grouped by default. flags are locally scoped and will only effect the supplied pattern, nothing more\"\"\"\n",
    "    if flags:\n",
    "        str_flags = decodeflags(flags)\n",
    "        pattern = r\"(?%s:%s)\"%(str_flags, pattern)\n",
    "    return Token(hre.group(pattern))\n",
    "\n",
    "\n",
    "def Word(initChars, bodyChars=None, min=1, max=0, exact=0, excludeChars=None):\n",
    "    \"\"\"Grouped by default. not implemented kwargs: asKeyword \"\"\"\n",
    "    \n",
    "    if max != 0 and min > max:\n",
    "        raise RuntimeError(\"min <= max needed\")\n",
    "\n",
    "    if excludeChars:\n",
    "        initChars = initChars + \"--\" + excludeChars\n",
    "        if bodyChars:\n",
    "            bodyChars = bodyChars + \"--\" + excludeChars\n",
    "\n",
    "    if exact == 1 or max == 1:\n",
    "        pattern = r\"[%s]{1}\"%(initChars)    \n",
    "    elif exact > 1:\n",
    "        if bodyChars:\n",
    "            pattern = r\"[%s]{1}[%s]{%s}\"%(initChars, bodyChars, exact-1)\n",
    "        else:\n",
    "            pattern = r\"[%s]{%s}\"%(initChars, exact)\n",
    "    elif max > 1:\n",
    "        if bodyChars:\n",
    "            pattern = r\"[%s]{1}[%s]{%s,%s}\"%(initChars, bodyChars, __builtin__.max(min-1,0), max-1)\n",
    "        else:\n",
    "            pattern = r\"[%s]{%s,%s}\"%(initChars, min, max)\n",
    "    else: # arbitrary upper bound\n",
    "        if bodyChars:\n",
    "            pattern = r\"[%s]{1}[%s]{%s,}\"%(initChars, bodyChars, __builtin__.max(min-1,0))\n",
    "        else:\n",
    "            pattern = r\"[%s]{%s,}\"%(initChars, min)\n",
    "\n",
    "    # group by default:\n",
    "    return Token(hre.group(pattern))\n",
    "\n",
    "        \n",
    "def SkipTo(self, expr, include=False):\n",
    "    \"\"\"Grouped by default. not supported: ignore=None, failOn=None.\n",
    "    \n",
    "    Token for skipping over all undefined text until the matched expression is found.\n",
    "    If C{include} is set to true, the matched expression is also parsed (the skipped text\n",
    "    and matched expression are returned as a 2-element list).  The C{ignore}\n",
    "    argument is used to define grammars (typically quoted strings and comments) that\n",
    "    might contain false matches.\n",
    "    \"\"\"\n",
    "    pattern = r\"(?:.(?!%s))*.\"%(expr)\n",
    "    if include:\n",
    "        pattern += expr\n",
    "    # group by default:\n",
    "    return Token(hre.group(self.pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def StringStart():\n",
    "    \"\"\"matches beginning of the text\"\"\"\n",
    "    return Token(r\"^\")\n",
    "\n",
    "def StringEnd():\n",
    "    \"\"\"matches the end of the text\"\"\"\n",
    "    return Token(r\"$\")\n",
    "\n",
    "def LineStart():\n",
    "    \"\"\"matches beginning of a line (lines delimited by \\n characters)\"\"\"\n",
    "    return Regex(r\"^\", regex.MULTILINE)\n",
    "\n",
    "def LineEnd():\n",
    "    \"\"\"matches the end of a line\"\"\"\n",
    "    return Regex(r\"$\", regex.MULTILINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Suppress(expr):\n",
    "    expr = deepcopy(expr)\n",
    "    expr.suppress()\n",
    "    return expr\n",
    "\n",
    "\n",
    "def And(iterable):\n",
    "    \"\"\"__dict__ of first element will be passed through And result \"\"\"\n",
    "    try:\n",
    "        gen = iter(iterable)\n",
    "        base = next(gen) + next(gen) # once (+) to have a new element\n",
    "        for expr in gen:\n",
    "            base += expr\n",
    "        return base\n",
    "    except StopIteration: # only one element\n",
    "        return next(iter(iterable))\n",
    "\n",
    "\n",
    "def MatchFirst(iterable):\n",
    "    \"\"\"__dict__ of first element will be passed through MatchFirst result \"\"\"\n",
    "    try:\n",
    "        gen = iter(iterable)\n",
    "        base = next(gen) | next(gen) # once (|) to have a new element\n",
    "        for expr in gen:\n",
    "            base |= expr\n",
    "        return base\n",
    "    except StopIteration: # only one element\n",
    "        return next(iter(iterable))\n",
    "    \n",
    "#Or __xor__ and Each __and__ are missing - takes more time to implement\n",
    "\n",
    "def Optional(expr):\n",
    "    cp = copy(expr)\n",
    "    cp.pattern = r\"%s?\" % hre.ensure_grouping(cp.pattern)\n",
    "    return cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Group(expr):\n",
    "    g = deepcopy(expr)\n",
    "    g.group()\n",
    "    return g\n",
    "\n",
    "def GroupLiftKeys(expr):\n",
    "    g = deepcopy(expr)\n",
    "    g.group(liftkeys=True)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OneOrMore(expr):\n",
    "    return Repeat(expr, min=1)\n",
    "        \n",
    "def ZeroOrMore(expr):\n",
    "    return Repeat(expr)\n",
    "\n",
    "def Repeat(expr, min=0, max=inf):\n",
    "    expr = deepcopy(expr)\n",
    "    expr.repeat(min=min, max=max)\n",
    "    return expr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(r'([abc]{3})', [?])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(r'([abc]{3})', ([?], {}, {'pattern': '([abc]{3})', 'liftedkeys': False, 'pseudo': False}))"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Count.reset()\n",
    "w = Word(\"abc\", exact=3)\n",
    "print w\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(r'([abc]{3})([abc]{3})?', [?,?])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(r'([abc]{3})([abc]{3})?', ([?, ?], {}, {'pattern': '([abc]{3})([abc]{3})?', 'liftedkeys': False, 'pseudo': False}))"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww = w + Optional(w)\n",
    "print ww\n",
    "ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(r'([abc]{3})([abc]{3})?', ([(r'([abc]{3})([abc]{3})?', ([?, ?], {}, {'pattern': '([abc]{3})([abc]{3})?', 'liftedkeys': False, 'pseudo': False}))], {}, {'pattern': '([abc]{3})([abc]{3})?', 'liftedkeys': False, 'pseudo': False}))"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gww = Group(ww)\n",
    "gww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(r'(([abc]{3})([abc]{3})?){1,}+', [Repeated(count=?, struct=(r'([abc]{3})([abc]{3})?', ([(r'([abc]{3})([abc]{3})?', ([?, ?], {}, {'pattern': '([abc]{3})([abc]{3})?', 'liftedkeys': False, 'pseudo': False}))], {}, {'pattern': '([abc]{3})([abc]{3})?', 'liftedkeys': True, 'pseudo': True})))])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(r'(([abc]{3})([abc]{3})?){1,}+', ([Repeated(count=?, struct=(r'([abc]{3})([abc]{3})?', ([(r'([abc]{3})([abc]{3})?', ([?, ?], {}, {'pattern': '([abc]{3})([abc]{3})?', 'liftedkeys': False, 'pseudo': False}))], {}, {'pattern': '([abc]{3})([abc]{3})?', 'liftedkeys': True, 'pseudo': True})))], {}, {'pattern': '(([abc]{3})([abc]{3})?){1,}+', 'liftedkeys': False, 'pseudo': False}))"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oomww = OneOrMore(gww)\n",
    "print oomww\n",
    "oomww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ParseResult.FLATTEN_SINGLETONS = True\n",
    "ParseResult.EMPTY_DEFAULT = \"EMPTYLIST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.ParseResult'>\n",
      "[[aaa,bcb],[ccc,ccc],[aac,[]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ParseResult at 0x7f76fd54e4d0 for Structure at 0x7f76fd55a8d0>"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"aaabcbccccccaac\"\n",
    "pr = oomww.parseString(data)\n",
    "\n",
    "print type(pr)\n",
    "print pr\n",
    "pr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 4,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
